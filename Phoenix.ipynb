{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "273fd2f4-c4b2-48e3-ab98-c21492bde5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing and training the model...\n",
      "Dataset loaded successfully!\n",
      "Shape of dataset: (1000, 6)\n",
      "\n",
      "Columns in your dataset:\n",
      "['Patient_Name', 'Age', 'Weight_kg', 'Height_cm', 'Blood_Pressure_mmHg', 'Disease']\n",
      "\n",
      "First few rows of your dataset:\n",
      "       Patient_Name  Age  Weight_kg  Height_cm  Blood_Pressure_mmHg  \\\n",
      "0      Ramesh Patel   10         29         93                  102   \n",
      "1     Sunita Pandey   12         21        103                  152   \n",
      "2  Santosh Kulkarni   11         19        112                  154   \n",
      "3       Swati Verma   32         80        152                   95   \n",
      "4      Sudha Pandey   30         57        177                   95   \n",
      "\n",
      "            Disease  \n",
      "0    Kidney Disease  \n",
      "1      Hypertension  \n",
      "2  Thyroid Disorder  \n",
      "3      Tuberculosis  \n",
      "4      Hypertension  \n",
      "\n",
      "Numeric columns in your dataset:\n",
      "['Age', 'Weight_kg', 'Height_cm', 'Blood_Pressure_mmHg']\n",
      "\n",
      "Using these features: ['Age', 'Weight_kg', 'Height_cm', 'Blood_Pressure_mmHg']\n",
      "Target column: Disease\n",
      "\n",
      "Handling missing values...\n",
      "\n",
      "Training the model...\n",
      "\n",
      "Model Accuracy: 0.3000\n",
      "\n",
      "Feature Importance:\n",
      "               feature  importance\n",
      "3  Blood_Pressure_mmHg    0.256304\n",
      "0                  Age    0.255247\n",
      "1            Weight_kg    0.246408\n",
      "2            Height_cm    0.242042\n",
      "\n",
      "Processing dataset and generating predictions...\n",
      "\n",
      "Making predictions for all rows...\n",
      "Completed dataset saved as 'completed_dataset.csv'\n",
      "\n",
      "Process completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class DiseasePredictionModel:\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.model = RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "    def train(self):\n",
    "        try:\n",
    "            df = pd.read_csv(\"C:\\\\Users\\\\Larren Pinto\\\\Downloads\\\\general_disease_diagnosis.csv\")\n",
    "            print(\"Dataset loaded successfully!\")\n",
    "            print(f\"Shape of dataset: {df.shape}\")\n",
    "            print(\"\\nColumns in your dataset:\")\n",
    "            print(df.columns.tolist())\n",
    "            print(\"\\nFirst few rows of your dataset:\")\n",
    "            print(df.head())\n",
    "            \n",
    "            numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "            print(\"\\nNumeric columns in your dataset:\")\n",
    "            print(numeric_columns.tolist())\n",
    "            \n",
    "            features = numeric_columns.tolist()\n",
    "            target_column = None\n",
    "            \n",
    "            for col in df.columns:\n",
    "                if 'condition' in col.lower() or 'disease' in col.lower() or 'diagnosis' in col.lower():\n",
    "                    target_column = col\n",
    "                    if col in features:\n",
    "                        features.remove(col)\n",
    "            \n",
    "            if not target_column:\n",
    "                print(\"\\nWarning: Could not automatically identify target column.\")\n",
    "                print(\"Available columns:\", df.columns.tolist())\n",
    "                target_column = input(\"Please enter the name of your target column: \")\n",
    "            \n",
    "            print(\"\\nUsing these features:\", features)\n",
    "            print(\"Target column:\", target_column)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(\"Error: The file 'general_disease_diagnosis.csv' was not found in the current directory.\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading the dataset: {str(e)}\")\n",
    "            return\n",
    "        \n",
    "        if df.isnull().sum().any():\n",
    "            print(\"\\nHandling missing values...\")\n",
    "            for column in df.columns:\n",
    "                if df[column].dtype in ['float64', 'int64']:\n",
    "                    df[column].fillna(df[column].mean(), inplace=True)\n",
    "                else:\n",
    "                    df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "        \n",
    "        X = df[features]\n",
    "        y = df[target_column]\n",
    "        \n",
    "        y_encoded = self.label_encoder.fit_transform(y)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "        \n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        self.feature_names = features\n",
    "        \n",
    "        print(\"\\nTraining the model...\")\n",
    "        self.model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        y_pred = self.model.predict(X_test_scaled)\n",
    "        \n",
    "        accuracy = np.mean(y_pred == y_test)\n",
    "        print(f\"\\nModel Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': features,\n",
    "            'importance': self.model.feature_importances_\n",
    "        })\n",
    "        print(\"\\nFeature Importance:\")\n",
    "        print(feature_importance.sort_values('importance', ascending=False))\n",
    "    \n",
    "    def predict(self, *feature_values):\n",
    "        if not hasattr(self, 'feature_names'):\n",
    "            raise ValueError(\"Model hasn't been trained yet!\")\n",
    "            \n",
    "        input_data = np.array([feature_values])\n",
    "        \n",
    "        input_scaled = self.scaler.transform(input_data)\n",
    "        \n",
    "        prediction_encoded = self.model.predict(input_scaled)\n",
    "        prediction = self.label_encoder.inverse_transform(prediction_encoded)\n",
    "        \n",
    "        probabilities = self.model.predict_proba(input_scaled)[0]\n",
    "        conditions_with_probs = list(zip(\n",
    "            self.label_encoder.classes_,\n",
    "            probabilities\n",
    "        ))\n",
    "        sorted_predictions = sorted(\n",
    "            conditions_with_probs,\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        return prediction[0], sorted_predictions\n",
    "    \n",
    "    def process_and_save_predictions(self):\n",
    "        df = pd.read_csv(\"C:\\\\Users\\\\Larren Pinto\\\\Downloads\\\\general_disease_diagnosis.csv\")\n",
    "        \n",
    "        df.to_csv('original_dataset.csv', index=False)\n",
    "        \n",
    "        df_completed = df.copy()\n",
    "        \n",
    "        for column in self.feature_names:\n",
    "            if df_completed[column].isnull().any():\n",
    "                df_completed[column].fillna(df_completed[column].mean(), inplace=True)\n",
    "        \n",
    "        predictions = []\n",
    "        probabilities_list = []\n",
    "        \n",
    "        print(\"\\nMaking predictions for all rows...\")\n",
    "        for _, row in df_completed[self.feature_names].iterrows():\n",
    "            pred, probs = self.predict(*row)\n",
    "            predictions.append(pred)\n",
    "            probabilities_list.append(dict(probs))\n",
    "        \n",
    "        df_completed['predicted_condition'] = predictions\n",
    "        \n",
    "        for condition in self.label_encoder.classes_:\n",
    "            df_completed[f'probability_{condition.replace(\" \", \"_\")}'] = [\n",
    "                probs.get(condition, 0) for probs in probabilities_list\n",
    "            ]\n",
    "\n",
    "        df_completed.to_csv('completed_dataset.csv', index=False)\n",
    "        print(\"Completed dataset saved as 'completed_dataset.csv'\")\n",
    "        \n",
    "        return df_completed\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Initializing and training the model...\")\n",
    "    model = DiseasePredictionModel()\n",
    "    model.train()\n",
    "    \n",
    "    print(\"\\nProcessing dataset and generating predictions...\")\n",
    "    completed_df = model.process_and_save_predictions()\n",
    "    print(\"\\nProcess completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "455a506a-d6d2-4714-9e5e-23ad45b1793a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.EnhancedDiseasePredictionModel at 0x256f0d2fcb0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class EnhancedDiseasePredictionModel:\n",
    "    def __init__(self):\n",
    "        self.pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('smote', SMOTE(random_state=42)),\n",
    "            ('model', RandomForestClassifier(random_state=42))\n",
    "        ])\n",
    "        self.grid_params = {\n",
    "            'model__n_estimators': [100, 200, 300],\n",
    "            'model__max_depth': [5, 10, 15],\n",
    "            'model__min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "        \n",
    "    def train(self):\n",
    "        try:\n",
    "            df = pd.read_csv(\"C:\\\\Users\\\\Larren Pinto\\\\Downloads\\\\general_disease_diagnosis.csv\")\n",
    "            # [Processing steps here...]\n",
    "            X, y = df[features], df[target_column]\n",
    "            \n",
    "            # Apply Grid Search with Cross-Validation\n",
    "            grid_search = GridSearchCV(self.pipeline, self.grid_params, cv=5, scoring='accuracy')\n",
    "            grid_search.fit(X, y)\n",
    "            best_model = grid_search.best_estimator_\n",
    "            \n",
    "            print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "            print(\"\\nCross-validated model accuracy:\", grid_search.best_score_)\n",
    "            \n",
    "            return best_model\n",
    "        except FileNotFoundError:\n",
    "            print(\"Error: The file 'general_disease_diagnosis.csv' was not found.\")\n",
    "            return None\n",
    "\n",
    "EnhancedDiseasePredictionModel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63a31106-dfa2-46d8-908b-9f52dacf675b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning hyperparameters for Random Forest...\n",
      "Random Forest Best F1 Score: 0.3216 with parameters: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "\n",
      "Tuning hyperparameters for SVM...\n",
      "SVM Best F1 Score: 0.2330 with parameters: {'C': 10, 'gamma': 1}\n",
      "\n",
      "Tuning hyperparameters for KNN...\n",
      "KNN Best F1 Score: 0.2839 with parameters: {'metric': 'manhattan', 'n_neighbors': 7, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"C:\\\\Users\\\\Larren Pinto\\\\Downloads\\\\general_disease_diagnosis.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.dropna(inplace=True)\n",
    "# Data preprocessing\n",
    "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "target_column = next((col for col in df.columns if 'condition' in col.lower() or \n",
    "                      'disease' in col.lower() or 'diagnosis' in col.lower()), None)\n",
    "\n",
    "# Fill missing values\n",
    "df.fillna(df.mean(numeric_only=True), inplace=True)\n",
    "df.fillna(df.mode().iloc[0], inplace=True)\n",
    "\n",
    "# Prepare features and target\n",
    "features = [col for col in numeric_columns if col != target_column]\n",
    "X = df[features]\n",
    "y = df[target_column]\n",
    "\n",
    "# Label encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Address class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y_encoded)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define models with optimized hyperparameters\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=500, max_depth=20, min_samples_split=3, class_weight='balanced', random_state=42),\n",
    "    \"SVM\": SVC(kernel='rbf', C=10, gamma=0.1, class_weight='balanced', probability=True, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=7, weights='distance', metric='minkowski')\n",
    "}\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "param_grids = {\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [100, 300, 500],\n",
    "        'max_depth': [10, 20, 30],\n",
    "        'min_samples_split': [2, 3, 5]\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'gamma': [0.01, 0.1, 1]\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        'n_neighbors': [5, 7, 9],\n",
    "        'metric': ['euclidean', 'manhattan'],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Train and evaluate each model with hyperparameter tuning\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTuning hyperparameters for {model_name}...\")\n",
    "    grid_search = GridSearchCV(model, param_grids[model_name], cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(f\"{model_name} Best F1 Score: {f1:.4f} with parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6231d158-2c5a-40c2-bb63-94be6c670ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
